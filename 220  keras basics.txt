# keras_basics_to_intermediate.py
# Learn Keras for deep learning with sample datasets

import numpy as np
import tensorflow as tf
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, Dropout
from tensorflow.keras.optimizers import Adam
from tensorflow.keras.datasets import mnist
from tensorflow.keras.utils import to_categorical
import matplotlib.pyplot as plt

# 1. Load and preprocess data (MNIST)
print("1. Loading and preprocessing MNIST data")
(x_train, y_train), (x_test, y_test) = mnist.load_data()
x_train = x_train.reshape(-1, 28*28).astype("float32") / 255.0
x_test = x_test.reshape(-1, 28*28).astype("float32") / 255.0
y_train = to_categorical(y_train)
y_test = to_categorical(y_test)

# 2. Define a simple model
print("\n2. Building a simple model")
model = Sequential([
    Dense(128, activation='relu', input_shape=(784,)),
    Dropout(0.2),
    Dense(64, activation='relu'),
    Dense(10, activation='softmax')
])
model.compile(optimizer=Adam(0.001), loss='categorical_crossentropy', metrics=['accuracy'])
model.summary()

# 3. Train the model
print("\n3. Training the model")
history = model.fit(x_train, y_train, epochs=5, batch_size=32, validation_split=0.2)

# 4. Evaluate the model
print("\n4. Evaluating the model")
loss, accuracy = model.evaluate(x_test, y_test)
print(f"Test Accuracy: {accuracy:.4f}")

# 5. Plot training history
plt.figure(figsize=(10, 4))
plt.subplot(1, 2, 1)
plt.plot(history.history['loss'], label="Train Loss")
plt.plot(history.history['val_loss'], label="Val Loss")
plt.title("Loss over epochs")
plt.legend()

plt.subplot(1, 2, 2)
plt.plot(history.history['accuracy'], label="Train Accuracy")
plt.plot(history.history['val_accuracy'], label="Val Accuracy")
plt.title("Accuracy over epochs")
plt.legend()
plt.tight_layout()
plt.savefig("keras_training_plots.png")
plt.show()

# 6. Predict sample
print("\n5. Predicting on test sample")
sample = np.expand_dims(x_test[0], axis=0)
pred = model.predict(sample)
print("Predicted class:", np.argmax(pred))
